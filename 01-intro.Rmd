# Wstęp

```{=latex}
\fancyhead[LO]{\textbf{\small{Wstęp}}}
\renewcommand{\headrulewidth}{0.5pt}
```

## Cel i znaczenie pracy magisterskiej

W historii ludzkości można odnotować wiele kryzysów, które dotknęły ogromnej liczby ludzi.
Wydarzenia te najczęściej miały dotkliwe konsekwencje finansowe, doprowadzając do biedy i&nbsp;bankructwa całe państwa.
W annałach historii można się doszukiwać wielu takich sytuacji, a ich przykładami mogą być:

- *tulipanowa gorączka* (1636-1637) -- lokowanie gotówki przez mieszkańców Amsterdamu w&nbsp;tulipanach doprowadziło do wyhodowania wyjątkowej odmiany tego kwiatu.
Wartość jego jednej cebulki była wówczas wyceniana na równowartość 40-letniego dochodu, przez co wielu kupców zaciągało niebotyczne kredyty.
Ceny tulipanów jednak zatrzymały się na poziomie, gdzie nikt nie był w stanie ich zakupić, a część handlujących nie wywiązywała się z dostaw.
To z kolei doprowadziło do końca spekulacji i gwałtownych obniżek cen [@tulips],

- *Great Depression* (1929-1932) -- największy kryzys gospodarczy w dziejach kapitalizmu, który swoim zasięgiem objął cały świat, z wykluczeniem ZSRR.
Przyjmuje się, że był on konsekwencją tzw. _czarnego czwartku_, kiedy to na nowojorskiej giełdzie gwałtownie spadły ceny niemal wszystkich notowanych akcji.
Poza finansowymi stratami, ludzie ucierpieli również z powodu niezwykle wysokiego bezrobocia, jak na przykład to na poziomie około 33\%, odnotowane w Stanach Zjednoczonych.
Kryzys przedłużył się dodatkowo w wyniku możliwości wymiany walut na złoto, co w szybkim tempie redukowało jego rezerwy w bankach centralnych.
Próbą zapobieżenia utraty kruszca, podniesiono stopy procentowe, co w konsekwewncji znacząco wpłynęło na produkcję przemysłową wielu krajów [@greatDepressionWiki],

- *upadek Lehman Brothers* (2007-2009) -- firma Lehman Brothers, która swoją wczesną historię wiązała głównie z handlem bawełną, z czasem przekształcona została w bank,
zajmujący się m.in. udzielaniem kredytów hipotecznych, emisją papierów wartościowych oraz finansowaniem nieruchomości.
Spółka przez wiele lat osiągała najlepsze wyniki finansowe spośród spółek amerykańskich, zasługując na miano "Najlepszego Banku Inwestycyjnego" w 2005 roku.
Zbiegło się to z tzw. _kryzysem subprime_ w Stanach Zjednoczonych, który dotyczył kredytów hipotecznych, udzielanych osobom o niskiej zdolności kredytowej.
Praktyka ta była obarczona dużym ryzykiem, a w wyniku obniżenia stóp procentowych przez amerykański bank centralny, kredyty te znacznie staniały, a przez to wzrosła ich dostępność i sektor prywatny zwiększył swoje zadłużenie o ok. 80 p.proc. w ciągu 7 lat.
Bank centralny wkrótce zdecydował się na podwyższenie stóp procentowych, co zaowocowało brakiem możliwości spłaty długów przez zadłużonych, oraz spadkiem cen papierów wartościowych, będącym konsekwencją ich masowym wykupywaniem.
Tym sposobem największy bank inwestycyjny Stanów Zjednoczonych ogłosił upadłość w 2008 roku, przez co indeksy giełdowe zaczęły błyskawicznie spadać [@lehmanBros].

Na przestrzeni ostatnich lat na światem wstrząsnęły również kolejne dramatyczne wydarzenia, mianowicie:

- __epidemia SARS-CoV-2__ w listopadzie 2019 -- pandemia wywołana chorobą _COVID-19_ jest powodowana przez koronawirusa _SARS-CoV-2_,
a pierwszy zidentyfikowany przypadek zachorowania na tę chorobę został zidentyfikowany w grudniu 2019 roku w Wuhan (Chiny).
Z uwagi na wysoką zaraźliwość wirusa i jego wariantów, przypadki zarażeń zaczęły się szybko mnożyć, co doprowadziło do ogłoszenia pandemii tej choroby 30 stycznia 2020 roku.
Pacjenci z potwierdzonym zakażeniem wirusem doświadczają objawów chorobowych związanych z układem oddechowym, tj. kaszel, duszności.
Dodatkowo zarażeni wykazywali oznaki osłabienia, nagłej utraty węchu i smaku oraz wielu innych dolegliwości.
Szczególnie dotkliwie choroba dotyka osoby starsze, o już osłabionym układzie odpornościowym, co jest jednym z istotnych czynników wysokiej jej śmiertelności [@covidMP].
Pandemia przyniosła znaczne skutki socjoekonomiczne, w tym szczególnie największą recesję od czasów *Great Depression* [@covidIMF].
Do 12 marca 2024 roku pandemia spowodowała ponad 7 milionów zgonów, będąc piątą co do wielkości najbardziej śmiertelną chorobą w historii.
[@covidWiki]
,

- __inwazja Rosji na Ukrainę__ w lutym 2022 -- eskalacja konfliktu rosyjsko-ukraińskiego, zapoczątkowanego w lutym 2014 roku poprzez aneksję Krymu oraz wojnę w Donbasie [@ukraineGenesisWiki].
w ciągu kolejnych lat nastąpiła eskalacja wojny, w konsekwencji której Rosja ogłosiła _specjalną operację wojskową_ [@ukraineTASS] mającą na celu wojnę błyskawiczną i przejęcie kontroli nad państwem i rządem ukraińskim.
Operacja w ciągu kolejnych miesięcy przerodziła się w brutalną wojnę dzięki silnemu oporowi wojsk ukraińskich oraz wsparciu państw europejskich oraz NATO.
W wyniku działań wojskowych Ukrainę opuściło ponad 5 milionów osób, które szukały azylu m.in. w Polsce, Rumunii, Rosji i na Węgrzech.
Natychmiastowym skutkiem inwazji stały się również sankcje gospodarcze nałożone przez świat na Federację Rosyjską, co spowodowało gwałtowny spadek wartości rubla rosyjskiego [@ukraineMoney].
Rosja w odpowiedzi zakazała swoim rezydentom przelewów walut obcych na konta zagraniczne, a także wymusiła płatności w rublach za surowce sprowadzane z Rosji, np. gaz.
Również gospodarka ogólnoświatowa doświadczyła kryzysu, powodując wzrost cen ropy i przenicy.
[@ukraineWiki]
.

Historia pokazuje, że zdarzenia dotykające wielu ludzi nie pozostają obojętne z perspektywy świata ekonomii.
Już wyżej wspomniane kryzysy miały znaczące podłoże finansowe i nie inaczej jest w przypadku dwóch najnowszych wydarzeń.
Aby zapobiec ich dotkliwym w skutkach reperkusjom, ekonomiści i naukowcy stosowali różne techniki, co szczegółowo opisane zostanie w dalszej części pracy.
Wyniki ich prac zostały opublikowane na łamach różnego rodzaju czasopism i publikacji
[@vanBergeijk2021pandemic;@shah2021mathematical;@fraguela2022moving;@hernandez2023mathematical]
.

Celem niniejszej pracy magisterskiej jest, podobnie jak w wyżej wspomnianych badaniach, analiza reakcji rynku polskiego na owe kryzysowe wydarzenia.
Wykorzystane zostaną znane metody z obszaru modelowania finansowego.
Idealnym narzędziem zdają się tu być modele przełącznikowe, za pomocą których możliwe będzie dopasowanie teoretycznych wartości do danych rynkowych,
a także wykonanie prognozy celem sprawdzenia dopasowania tych modeli.
Po przeprowadzeniu badań podsumowane zostaną ich wyniki oraz opisana zostanie siła wpływu, jaki globalne zmiany wywierają na rodzimą gospodarkę.
Informacje te mogą posłużyć do dalszego konstruowania modeli mających za zadanie negować skutki globalnych kryzysów i zapobiegać ich finansowym efektom.

Oczywiście analiza ta nie jest wyczerpująca
-- ze względu na różnorakie ograniczenia (czasowe i komputacyjne) ograniczony został zakres badania,
co może ostatecznie nie dawać pełnego obrazu sytuacji panującej na warszawskiej giełdzie.
Mimo to obrany horyzont czasowy, wraz z przyjętym wolumenem badanych i zakresem weryfikowanych modeli ekonometrycznych,
pozwalają przypuszczać, że wyniki niniejszego badania są wiarygodne i wnioski z niego wyciągnięte mają swoje uzasadnienie w rzeczywistości.

## Modele rynków finansowych

### Rynek finansowy

Pojęcie **rynku finansowego** nie jest jednoznacznie określone i w różnych źródłach można przytoczyć różne jego formy.
Według jednej z nich rynek finansowy jest "miejscem zawierania transakcji mających za przedmiot szeroko rozumiany kapitał finansowy".
Z uwagi jednak na globalną naturę gospodarki we współczesnym świecie, trudno powiązać rynek finansowy z konkretnym miejscem.
Z tego też względu można powiedzieć o rynku finansowym, że jest to "ogół transakcji papierami wartościowymi"
[@wisla2008, s. 33]
.

Transakcje te zawierane są za pomocą **instrumentów finansowych**, które pozwalają na transfer, wymianę lub przechowywanie środków pieniężnych.
Pełna lista istniejących instrumentów jest długa i można ją podzielić według różnych kryteriów [@ifirmaInstrumenty;@krzywda2005klasyfikacja].
Na potrzeby niniejszej pracy istotnymi instrumentami finansowymi są *akcje* oraz *indeksy giełdowe*.

**Akcja** jest papierem wartościowym dającym prawo jej posiadaczowi do udziału w spółce akcyjnej, która jest jej emitentem.
Nabywca akcji staje się _akcjonariuszem_ tej spółki, wobec czego jest współwłaścicielem jej majątku i otrzymuje prawa do:

- podziału wypracowanego przez spółkę zysku -- dywidendy,
- pobierania nowych akcji,
- uczestnictwa w walnych zgromadzeniach innych akcjonariuszy,
- majątku spółki, gdyby ta została zlikwidowana.

Akcje mogą być imienne lub na okaziciela, a jako papier wartościowy cechują się ceną nominalną, rynkową oraz emisyjną.
Mogą być emitowane jedynie przez spółki akcyjne i komandytowo-akcyjne
[@akcjaEZ].
Na rynku wtórnym (np. na giełdzie) inwestorzy mają możliwość zakupu i sprzedaży akcji różnych spółek, jakie są na nim notowane.
W marcu 2024 roku na rynku podstawowym _Giełdy Papierów Wartościowych_ w Warszawie prowadzone są notowania 409 spółek, w tym 367 krajowych,
o łącznej kapitalizacji 1,5 bln zł [@gpwStat].

**Indeksem giełdowym** nazywa się wskaźnik, który służy do monitorowania przebiegu cen papierów wartościowych spółek notowanych na giełdzie.
Jest to byt umożliwiający śledzenie trendów panujących na rynkach finansowych, bez konieczności monitorowania dużej liczby cen akcji poszczególnych spółek.
Do budowy indeksu giełdowego wykorzystuje się takie informacje, jak ceny akcji i ich wartości rynkowe.
Te wartości są porządkowane za pomocą ustalonych przez giełdę wag oraz uśredniane średnią geometryczną lub arytmetyczną.
Na giełdzie warszawskiej funkcjonuje kilka indeksów, a największymi z nich są:

- WIG -- pierwszy indeks giełdowy, obliczany od 1991 roku. Obejmuje wszystkie spółki notowane na _Głównym Rynku GPW_, spełniające kryteria uczestnictwa w indeksach,
- WIG20 -- obliczany od 1994 roku na podstawie wartości portfela akcji 20 największych i najbardziej płynnych spółek z _Głównego Rynku GPW_. Bierze pod uwagę jedynie ceny transakcji, nie uwzględniając wartości dochodów z dywidend,
- mWIG40 -- kontynuacja indeksu MIDWIG, obliczany od 1997 roku. Obejmuje 40 średnich spółek notowanych na _Głównym Rynku GPW_ i, podobnie jak WIG20, jest indeksem typu cenowego. Wyklucza spółki wchodzace w skład indeksów WIG20,
- sWIG80 -- kontynuacja indeksu WIRR obliczanego od 1994 roku. W jego skład wchodzi 80 małych spółek notowanych na _Głównym Rynku GPW_. Tak jak WIG20 i mWIG40, jest indeksem typu cenowego i nie bierze pod uwagę spółek należących do tych indeksów.

[@indeksBI;@wigGpwBenchmark]

### Szeregi czasowe danych finansowych

Pod pojęciem __modelowania__ zazwyczaj kryje się ogół narzędzi teoretycznych, mających na celu ustalić tendencje wpływające na wartość danego instrumentu na rynku finansowym,
a w konsekwencji przewidzieć jego przyszłą wartość.
Aby ten cel osiągnąć, stosuje się wiele różnych modeli matematycznych, o różnych stopniach skomplikowania i liczbach parametrów.
Aby sensownie usystematyzować dane finansowe wykorzystuje się pojęcie **szeregu czasowego** -- ciągu obserwacji ilustrującego przebieg zjawiska w czasie.
Dane w szeregu czasowym są mogą reprezentować pomiary dzienne, miesięczne, roczne lub dowolny inny interwał czasowy.

Dane przedstawiające zmienność zjawiska w czasie są zazwyczaj zbudowane z kilku składowych jako następstw różnych czynników zewnętrznych.
Można tu wyróżnić [@gusSzeregCzas]:

- trend (tendencję rozwojową) --
skłonność do jednokierunkowych zmian obserwowanych w długim okresie czasu.
Wzrost średniej ceny towaru na przestrzeni wielu lat pomimo jej wahań w interwale miesięcznym jest przykładem trendu,

- wahania cykliczne --
związane zazwyczaj z cyklem koniunkturalnym gospodarki, reprezentują długookresowe, powtarzające się wahania wartości wokół trendu,

- sezonowość --
podobnie jak wahania cykliczne, są przejawem oscylacji wartości szeregu czasowego wokół trendu.
Wahania sezonowe jednak dotyczą zmian w horyzoncie czasowym do jednego roku.
Za przykład może tu posłużyć wpływ pór roku na wysokość sprzedaży produktu,

- część przypadkową --
komponent szeregu czasowego niemożliwy do wyjaśnienia przez powyższe.
Zawiera losowe wahania szeregu wokół pewnego ustalonego poziomu.

Modele matematyczne i ekonometryczne mają na celu wyjaśnienie wpływu czynników systematycznych w badanych szeregach czasowych,
co pozwala na prognozowanie dalszego przebiegu zjawiska lub analizę jego sezonowości.
Dla danych finansowych szczególnie istotne jest modelowanie takich wielkości, jak:

1. wartości (ceny) akcji,
2. indeksy giełdowe,
3. obligacje,
4. kursy walut,
5. ceny surowców,
6. stopy procentowe rynku międzybankowego.

Dane dla punktów 1. i 2. są dostępne na stronach internetowych instytucji giełd oraz innych organizacji/osób i są głównym tematem tej pracy.
Katalogowane są one w odstępach dziennych, uwzględniając dni sesyjne, tj. dni, w których giełda jest otwarta.
Dla szeregów czasowych reprezentujących dane finansowe częstą praktyką jest konstruowanie szeregu **logarytmicznych stóp zwrotu** z inwestycji z wykorzystaniem Wzoru \@ref(eq:return):

\begin{equation} (\#eq:return)
r_{t} = \ln\nz{\frac{x_{t}}{x_{t-1}}} \cdot 100
\end{equation}
gdzie $x_i$ jest wartością szeregu czasowego $(x)$ w momencie $t$.
Zabieg ten znajduje swoje zastosowanie ze względu na kilka czynników [@wzrSzeregiCzas]:

- ujednolicenie danych -- zastosowanie logarytmu pozwala na znormalizowanie wartości, usuwając zaburzenia wynikające ze skali szeregu,
- stabilność statystyczna -- transformacja ta nadaje szeregowi czasowemu odporności na wahania krótkoterminowe, co pomaga w prognozach na dłuższe okresy,
- modelowanie zmienności -- analiza stóp zwrotu jest przydatna na potrzeby modeli poruszanych w badaniu, które są skoncentrowane na badaniu zmienności zjawiska zamiast jego rzeczywistych wartości.

Ze względu na te wnioski, obliczenia w niniejszej pracy będą się odbywały w odniesieniu do szeregów logarytmicznych stóp zwrotu badanych spółek i indeksów.

### Modele średniej i wariancji warunkowej

W obrębie niniejszego badania rozważane będą dwa rodzaje modeli szeregów czasowych: modele średniej warunkowej oraz wariancji warunkowej.
Dodatkowym elementem tego typu równań jest również czynnik losowy $\epsilon$, zwany **innowacją**, reprezentujący część przypadkową danych.
Dla danych finansowych poruszanych na łamach tej pracy zmienną objaśnianą jest **wartość szeregu** logarytmicznych stóp zwrotu **w danym momencie** $r_t$.

**Model średniej warunkowej** ma na celu wyjaśnienie zmienności szeregu czasowego za pomocą równania liniowego,
uzależniając średni poziom szeregu czasowego od sumy iloczynów pewnych parametrów oraz zmiennych objaśniających.
Klasa modeli przybliżona w dalszej części badania korzysta ze zjawiska **autoregresji** szeregu czasowego,
tj. uzależnienia wartości obecnej szeregu od jego wartości w wybranych momentach przeszłych.
Ma to swoje zastosowanie w klasie modeli ARMA (_autoregressive - moving average_), którego budowę przedstawia Wzór \@ref(eq:arma).

\begin{equation} (\#eq:arma)
x_t =
  \sum_{i=1}^{p} a_i x_{t-i}
  + \sum_{j=1}^{q} b_i \epsilon_{t-i}
  + \epsilon_{t}
\end{equation}

Model składa się z dwóch komponentów:

- część autoregresyjna (AR): model uzależnia wartość obecną szeregu czasowego od jego kolejnych $p$ przeszłych wartości,
- część średniej ruchomej (MA): wartość szeregu w danym momencie jest zależna od kolejnych $q$ wartości przeszłych innowacji.

Model ARMA w postaci takiej, jak przedstawiono za pomocą Wzoru \@ref(eq:arma), sprawdza się w przypadku stacjonarnych szeregów czasowych,
gdzie _pamięć szeregu_, tj. możliwość zaobserwowania wpływu danych historycznych na obecne, obejmuje względnie niskie opóźnienia i jest krótkotrwała.
W przeciwnym przypadku można domniemać istnienie zależności długotrwałych i nieliniowych.

**Modele wariancji warunkowej** pomagają w interpretacji zależności długookresowych szeregu czasowego,
a w ich implementacji korzystają z równań kwadratowych.
Jak wskazuje nazwa, modele tej klasy mają na celu modelowanie wariancji szeregu czasowego.
Dokonuje się tego z wykorzystaniem reszt z modelu liniowego (np. ARMA), a w ogólności model taki można opisać Wzorem \@ref(eq:arch-base).
Uzależnia on wartość stopy zwrotu $r_t$ od modelowanej średniej $\mu_t$ oraz reszty z modelu $y_t$.

\begin{equation} (\#eq:arch-base)
r_t = \mu_t + y_t, 
\quad
y_t = \sigma_t \epsilon_t,
\quad
\epsilon_t \sim IID(0, 1)
\end{equation}

Historycznie pierwszym z modeli należących do tej klasy jest model ARCH(q) (_autoregressive conditional heteroskedasticity_) [@engleARCH],
w którym wariancja warunkowa modelu jest opisywana przez kwadraty reszt z modelu (Wzór \@ref(eq:arch)).

\begin{equation} (\#eq:arch)
\sigma_t^2 =
  \omega
  + \sum_{i=1}^{q} \alpha_i y^2_{t-i}
\end{equation}

Wadą tego modelu w kontekście rynków finansowych jest konieczność stosowania wysokiej liczby opóźnień $q$,
co prowadzi do skomplikowanego modelu i wymaga dłuższych horyzontów czasowych.
Naprzeciw temu problemowi występuje model GARCH(q, p) [@bollerslevGARCH], w którym w modelowaniu wariancji warunkowej biorą udział również przeszłe wartości wariancji,
co reprezentuje Wzór \@ref(eq:garch).

\begin{equation} (\#eq:garch)
\sigma_t^2 =
  \omega
  + \sum_{i=1}^{q}
    \alpha_i y^2_{t-i}
  + \sum_{j=1}^{p}
    \beta_j \sigma^2_{t-j}
\end{equation}

Istotnym czynnikiem, jaki pojawia się przy modelowaniu danych finansowych jest **efekt dźwigni**.
Model GARCH zakłada, że dodatnie i ujemne stopy zwrotu mają taki sam wpływ na decyzje podejmowane przez inwestora.
Nie jest to jednak realne założenie, ponieważ spadki cen instrumentów finansowych są zwykle bardziej nagłaśniane aniżeli ich wzrosty.
Jest to naturalne dla człowieka zachowanie i występuje jako domena ostrożnych inwestorów,
bardziej skłonnych do wczesnej likwidacji inwestycji.
Za ilustrację tych zachowań odpowiada koncept **krzywej wpływu informacji**, która jest elementem dwóch kolejnych rozpatrywanych w tej pracy modeli.
Model GJR-GARCH(q, p) [@glostenGJR] (Wzór \@ref(eq:gjr-garch)) jest rozbudowaniem modelu GARCH,
przy czym uwzględnia on dodatkowo asymetrię informacji w części równania odpowiedzialnej za wpływ kwadratów reszt.
Powoduje to, że negatywne wartości tego szeregu mają większy wpływ na modelowaną zmienność.

\begin{equation} (\#eq:gjr-garch)
\sigma_t^2 =
  \omega
  + \sum_{i=1}^{q} \nz{
    \alpha_i y^2_{t-i} + \gamma_i y^2_{t-i} \doubleI(y_{t-i} < 0)
  }
  + \sum_{j=1}^{p}
    \beta_j \sigma^2_{t-j}
\end{equation}

Podobną aplikację krzywej wpływu informacji wykorzystuje model EGARCH(q, p) [@nelsonEGARCH].
Rozwiązuje on problemy modelu GARCH, takie jak uproszczenie interpretacji persystencji szoków i monitorowanie korelacji pomiędzy zwrotami a innowacjami zmienności.
Jak wskazuje Wzór \@ref(eq:egarch), modyfikacja opiera się na modelowaniu logarytmu wariancji.

\begin{equation} (\#eq:egarch)
\ln \sigma_t^2 =
  \omega
  + \sum_{i=1}^{q}
    \alpha_i \nz{
      \abs{y_{t-i}} - \doubleE \abs{y_{t-i}}
    } + \gamma_i y_{t-i}
  + \sum_{j=1}^{p}
    \beta_j \sigma^2_{t-j}
\end{equation}

Innym podejściem będącym rozwinięciem idei modeli heteroskedastyczności warunkowej jest uwzględnienie w modelu wpływu czynników zewnętrznych,
takich jak sezonowość lub zmienność innych szeregów czasowych (np. innych instrumentów finansowych).
W tym celu opracowany został model GARCH-X [@hwangGARCHX], w równaniu którego (Wzór \@ref(eq:garchx)) pojawia się składnik odpowiedzialny za siłę tychże zależności.
Owa siła sterowana jest niezależnie dla każdej z $L$ dodatkowych zmiennych.

\begin{equation} (\#eq:garchx)
\sigma_t^2 =
  \omega
  + \sum_{i=1}^{q}
    \alpha_i y^2_{t-i}
  + \sum_{j=1}^{p}
    \beta_j \sigma^2_{t-j}
  + \sum_{l=1}^{L}
    \sum_{k=1}^{r}
    \lambda_{l, k} w^2_{t-k}
\end{equation}

We wszystkich powyższych modelach rozkład innowacji $\epsilon_t$ jest przyjmowany jako rozkład IID (szereg niezależnych zmiennych losowych o jednakowym rozkładzie).
W klasycznych rozważaniach rolę tę spełnia rozkład normalny, jednak do zastosowań finansowych wykorzystuje się również inne, uwzględniające dodatkowe czynniki, jakie jak leptokurtoza rozkładu.
Poniżej przedstawiono rozkłady innowacji najczęściej stosowane w modelowaniu szeregów finansowych, wraz z ich parametrami:

- rozkład normalny -- średnia $\mu$, wariancja $\sigma^2$,
- rozkład t Studenta -- liczba stopni swobody (kształt) $\nu$,
- rozkład skośny t Studenta -- liczba stopni swobody $\nu$, skośność $\xi = \exp(\lambda)$
- rozkład GED [@nelsonEGARCH, s. 352] -- kształt $\nu$.

Intuicyjnym zagadnieniem podczas modelowania wariancji warunkowej jest identyfikacja okresów zwiększonej i zmniejszonej zmienności w badanym horyzoncie czaowym.
Naprzeciw temu problemowi wychodzi idea *modeli przełącznikowych*, a w szczególności rozważany na łamach tej pracy model przełącznikowy Markowa [@packageMSGARCH].
Opierają się one na połączeniu wielu modeli takich, jak te opisane powyżej, i implementację mechanizmu wyboru, który z tych modeli jest stosowany w którym momencie czasowym.
Tę rolę pełni *proces Markowa*, za pomocą którego można zdefiniować proces stanu (reżimu) $s_t$, identyfikujący wybrany model w momencie $t$.
W modelu przełącznikowym Markowa ARMA-GARCH parametry modelu są uzależnione od obecnego reżimu.
Oznacza to, że w wariancie dwóch reżimów estymowane są dwa zestawy parametrów, po jednym dla każdego z rozpatrywanych modeli.

### Kwantyfikacja poprawności modelu

Proces __dopasowania__ modelu teoretycznego do danych rzeczywistych polega na znalezieniu jego parametrów tak, aby zminimalizować _błąd dopasowania_, tj. absolutną różnicę pomiędzy wartością teoretyczną a wartością rzeczywistą.
Określa się wiele rodzajów błędów, ale do najczęściej wyróżniach w badaniach zalicza się te opisane poniżej.
Dla szeregu wartości modelowanych $(\hat{y}_i)$ formułuje się miary takie, jak **RMSE** (_Root Mean Square Error_) oraz **MAPE** (_Mean Absolute Percentage Error_) o następujących wzorach:

\begin{equation} (\#eq:errors)
RMSE = \sqrt{
  \frac{1}{n} \sum_{i=1}^{n}
    \nz{\hat{y}_i - y_i}^2
}
\qquad
MAPE = \frac{1}{n} \sum_{i=1}^{n}
  \frac{\abs{\hat{y}_i - y_i}}{y_i}
\end{equation}

Oczywiście do każdych danych istnieje możliwość dopasowania kilku różnych modeli, wobec czego zachodzi potrzeba porównania jakości wykorzystanych modeli.
W tym celu stosuje się __kryteria informacyjne__ -- wskaźniki opierające się na wartości funkcji wiarogodności $L$, które pozwalają na wyłonienie optymalnego modelu, który najwierniej opisuje dane zjawisko.
Podobnie jak w przypadku różnych rodzajów błędów, istnieje kilka kryteriów informacyjnych, stosowanych przy modelowaniu danych.
Wszystkie kryteria informacyjne opierają się na tej samej zasadzie
-- na zadany model nakładają karę za skomplikowanie modelu, która rośnie wraz z liczbą parametrów modelu $k$,
a rzadziej z wielkością próby $n$.
Wartości kryterium bliższe 0 informują o lepszej jakości dopasowania modelu.
Do najpopularniejszych kryteriów informacyjnych należą:

- kryterium Akaike [@akaikeAIC]:
$$
AIC = 2k - 2 \ln L
$$
Do obliczenia tego kryterium informacyjnego wymagana jest jedynie wiedza na temat liczby parametrów modelu $k$ oraz wartość funkcji wiarogodności $L$.
Stały współczynnik kary równy 2 sprawia, że jest to najbardziej penalizujące kryterium pod względem liczby parametrów,

- kryterium Schwarza [@schwarzBIC]:
$$
BIC = k \ln n - 2 \ln L
$$
Rozwinięcie kryterium informacyjnego Akaike, gdzie dodatkowo karą za złożoność modelu obarczana jest wielkość próby $n$,

- kryterium Hannana-Quinna [@hannanHQC]:
$$
HQC = 2k \ln(\ln n) - 2 \ln L
$$
Rzadziej stosowane kryterium, które w stosunku do BIC umniejsza karę za wielkość próby $n$.

Każde z powyższych kryteriów ma swoje zalety i środowiska naukowe preferują wykorzystanie konkretnego z nich częściej niż innych.
Powoduje to również uproszczenia w edukowaniu o istnieniu tychże kryteriów i prowadzi do nadmiernie zlaicyzowanego przeświadczenia o bezwzględnych korzyściach pewnych kryteriów nad pozostałymi.
Te przesłanki są przedmiotem badań ekspertów i, chociaż mają one pewne podłoże naukowe, ostatecznie nie są sztywnymi regułami [@zhangKryteriaInformacyjne].

Zasadność zastosowania modeli ARMA oraz GARCH może zostać potwierdzona przez liczne **testy statystyczne**.
Testem statystycznym nazywamy formułę, która pozwala na określenie prawdopodobieństwa wystąpienia określonej hipotezy
i jest on narzędziem dającym argumenty za jej odrzuceniem.
Na budowę testu statystycznego składają się:

- weryfikowana *hipoteza statystyczna*, która może zostać odrzucona tudzież nie,
- *statystyka testowa*, służąca do pomiaru sprawdzanego zjawiska w oparciu o dane z próby,
- *poziom istotności*, poniżej którego hipotezę można uznać za fałszywą.

W obrębie badania poziom istotności wszystkich testów statystycznych został przyjęty jako $\alpha = 0.05$,
a spośród dostępnych testów wykorzystane zostały testy opisane poniżej. Do każdego z nich podano wzór oraz rozkład statystyki testowej przy prawdziwości hipotezy zerowej.
Informacje te nie są kompleksowe, a po więcej szczegółów czytelnika odsyła się do opracowań źródłowych.

- Test normalności rozkładu zmiennej losowej -- test Shapiro-Wilka [@shapiroTest], którego $H_0$ zakłada, że dane cechują się rozkładem normalnym:
\begin{equation}
W = \frac{
  \nz{\sum_{i=1}^n a_i y_{(i)}}^2
}{
  \sum_{i=1}^n \nz{y_i - \bar{y}}^2
}
\end{equation}
Dla klarowności zapisu pominięto definicję wartości $a_i$ oraz $y_{(i)}$.
Rozkład statystyki $W$ nie ma nazwy, a jego wartości brzegowe są obliczane za pomocą symulacji metodą Monte Carlo;

- Test autokorelacji rzędu $l$ w obrębie szeregu czasowego -- test Ljung-Boxa [@boxTest], którego $H_0$ zakłada brak autokorelacji w szeregu czasowym:
\begin{equation}
Q = n(n+2) \sum_{k=1}^{l} \frac{\hat{\rho}^2_k}{n-k}
\qquad
Q \sim \chi^2(l)
\end{equation}
gdzie $n$ jest wielkością próby, $l$ stopniem testowanego opóźnienia, a $\hat{\rho}_k$ autokorelacją próby przy opóźnieniu $k$;

- Testy na występowanie efektu ARCH w resztach z modelu liniowego dla szeregu czasowego
  - test McLeoda-Li [@mcLeodLiTest], zakładający brak efektu ARCH przy $H_0$ poprzez brak autokorelacji pomiędzy szeregami kwadratów reszt z modelu liniowego.
    Test ten jest tożsamy z testem Ljung-Boxa, z jedyną różnicą w danych wykorzystanych do obliczenia statystyki testowej;

  - test Engle'a [@engleARCH] przeprowadzany dla opóźnienia $l$ bada hipotezę zerową mówiącą o braku autokorelacji w kwadratach reszt z modelu liniowego:
    \begin{equation}
    LM = (n - l) R^2
    \qquad
    LM \sim \chi^2(l)
    \end{equation}
    Wzór na statystykę testową wykorzystuje $R^2$ -- współczynnik determinacji dopasowania regresji liniowej do modelu;

  - test KPSS [@KPSSTest], którego $H_0$, przeciwnie do powyższych testów, zakłada pierwszy stopień integracji szeregu czasowego, tj. obecność efektu ARCH:
    \begin{equation}
    KPSS = \frac{1}{n^2} \sum_{i=1}^n \frac{S_i^2}{\hat{\sigma}^2}
    \qquad
    S_i = \sum_{j=1}^i e_j
    \end{equation}
    gdzie $\hat{\sigma}^2$ jest estymatorem wariancji modelu. Rozkład tej statystyki również jest obliczany symulacyjnie.


## Przegląd pakietów statystycznych

Do zagadnienia estymacji modeli szeregów czasowych można wykorzystać różne narzędzia, pozwalające na przeprowadzanie wielu skomplikowanych kalkulacji.
Najczęstszymi wyborami badaczy zajmującymi się tymi zagadnieniami są języki wspierające budowę skomplikowanych równań,
a także pozwalające na usystematyzowanie wyników swoich obliczeń.
W dalszej części tego rozdziału omówione zostaną popularne pakiety statystyczne, z jakimi można się spotkać przy okazji poruszania problemu analizy szeregów czasowych.

### R

Do przeprowadzenia wszelkich obliczeń i symulacji w niniejszej pracy wykorzystano środowisko **R**.
Jest to otwartoźródłowy język programowania i środowisko do analizy danych oraz tworzenia grafik,
powszechnie używane w statystyce, analizie danych, uczeniu maszynowych oraz badaniach operacyjnych.
Charakteryzuje się bogatym zestawem bibliotek (pakietów), które umożliwiają wykonywanie różnorodnych analiz i wizualizacji danych [@R].

Na potrzeby tej pracy użyte zostały pakiety zaprojektowane do pracy z szeregami czasowymi oraz modelami ekonometrycznymi.
Do pracy z modelami GARCH zastosowano dwie z najpopularniejszych bibliotek zaprojektowanych do tego celu:

- `rugarch` -- pakiet, którego celem jest zapewnienie elastycznego i bogatego środowiska do modelowania i testowania modeli GARCH.
Implementuje różnego rodzaju testy statystyczne i metody tworzące wykresy, a także narzędzia do prognozowania i symulowania wartości modeli
[@packageRugarch, s. 3].
Zastosowany został do modelowania modeli z zastosowaniem zewnętrznych regresorów, oferując subiektywnie najbardziej przystępny sposób przekazania tych danych do programu spośród innych oferowanych rozwiązań.
- `MSGARCH` -- implementacja kompleksowego zestawu funkcjonalności na potrzeby modelu przełącznikowego Markowa z zastosowaniem modeli GARCH,
w szczególności dopasowywania, filtrowania, prognoz i symulacji.
Udostępnia również funkcje związane z obliczaniem wartości zagrożonej oraz _Expected Shortfall_.
Jest skoncentrowany na modelowaniu wariancji warunkowej, wobec czego nie implementuje równania średniej warunkowej
[@packageMSGARCHDocs, s. 2].
W niniejszej pracy spełnia oczywiście zadanie estymacji modeli przełącznikowych Markowa.
Oferuje przejrzystą dokumentację i potężne narzędzia, pozwalające na potencjalne rozszerzenie modeli,
co z dodatkową mocą obliczeniową może prowadzić do porównania większej liczby odpowiadających modeli.

Podczas badania wykorzystano również różne inne pakiety pozwalające na generowanie wykresów i tabel, a także płynnego przetwarzania danych,
m.in. `ggplot2` [@packageGgplot2] oraz `knitr` [@packageKnitr].
Dodatkowo warto wspomnieć o pakiecie `bookdown` [@packageBookdown], który pozwolił na doprowadzenie niniejszej pracy do jej obecnej postaci.

### Ox

Chociaż język R jest popularnym narzędziem w wielu środowiskach naukowych,
jest to jednak jedna z wielu technologii wykorzystywanych do modelowania danych statystycznych.
W kręgach nauk ekonomicznych znanym narzędziem do analizy finansowych szeregów czasowych jest program **OxMetrics** [@packageOxMetrics].
Składa się na niego rodzina pakietów, które dostarczają zintegrowane rozwiązania na potrzeby analizy, prognoz i modelowania danych przekrojowych i panelowych.
Samo środowisko pakietu OxMetrics jest oparte o język Ox.
Jest to obiektowy, macierzowy język programowania, zawierający szeroki wachlarz funkcji matematycznych i statystycznych.
Jego głównymi cechami są szybkość obliczeń, bogaty zestaw pakietów i dobrze zaprojektowana składnia, upraszczająca pracę z kodem.
W skład środowiska OxMetrics wchodzą pakiety pozwalające m.in. na:

- konstruowanie modeli ekonometrycznych (pakiet `PcGive`),
- estymację i prognozowanie modeli klasy GARCH (pakiet `G@RCH`),
- statystyczną/ekonometryczną analizę szeregów czasowych, a także ich modelowanie i predykcję (pakiet `STAMP`) [@packageOx].

Innym programem pozwalającym na kompleksową analizę szeregów czasowych jest pakiet **Time Series Modelling**.
Korzystając również z języka Ox, pozwala na estymację i prognozę różnych modeli szeregów czasowych:
ARIMA, ARFIMA, różnych wariantów GARCH, FIGARCH, APARCH i EGARCH, modeli dwuliniowych, przełącznikowych Markowa oraz wielu innych.
Większość z parametrów estymowanych modeli można swobodnie konfigurować za pomocą intuicyjnego interfejsu graficznego,
co pozwala na zaprojektowanie niemal dowolnego modelu danych.
System równań można również rozszerzyć o analizę wartości zagrożonej.
Oprogramowanie posiada także obszerne możliwości graficzne, pozwalające na tworzenie wykresów przebiegów szeregów czasowych, analizy ich rozkładów oraz innych, np. korelogramów
[@packageTSM].

### Python

Dla użytkowników z bardziej obszerną wiedzą programistyczną dostępne są również narzędzia w innych językach.
Skutkiem wysokiej popularności języka **Python**, znanego z posiadania szerokiego zestawu bibliotek rozszerzających jego działanie,
jest rozwój pakietów do tego języka skoncentrowanych na analizie modeli szeregów czasowych.

- Na potrzeby analizy modeli ARIMA jest to m.in. pakiet `pmdarima`.
Jego celem jest implementacja funkcji `auto.arima` z języka R w środowisku Python,
dzięki czemu aspirujący analitycy danych mają możliwość przeprowadzania analiz bez potrzeby nauki nowego języka.
Zainspirowany biblioteką `scikit-learn`, skupiającą się na rozwiązaniach z dziedziny uczenia maszynowego,
wykorzystuje znany użytkownikom model programistyczny pozwalający na przejrzystą i kompleksową analizę [@packagePythonPmdarima].

- Do budowania modeli GARCH popularną biblioteką jest `arch`.
Jest on zaprojektowany do modelowania zmienności warunkowej za pomocą różnych modeli klasy GARCH (GARCH, GJR, TARCH, EGARCH)
a także na prognozowanie zmienności warunkowej oraz analizę wartości zagrożonej [@packagePythonArch].

- Na analizę modeli przełącznikowych Markowa natomiast pozwala pakiet `statsmodels`.
Jest to biblioteka pozwalająca na pracę z wieloma różnymi modelami statystycznymi,
pozwalając na przeprowadzanie testów oraz eksploracji danych.
Nazewnictwo funkcji jest tutaj bardziej zainspirowane językiem R,
na co składa się m.in. sposób formułowania zależności między zmiennymi czy przywoływanie podsumowań.
Implementuje także budowę modeli przełącznikowych, takich jak model Markowa [@packagePythonStatsmodels].

### Julia

Ostatnim z języków programowania, o jakich warto wspomnieć na łamach niniejszej pracy, jest **Julia**.
Jest to otwartoźródłowy język zaprojektowany w 2017 roku z myślą o wysokiej wydajności,
jaką osiąga za pomocą kompilacji programów do kodu maszynowego.
Jako język programowania cechuje się dynamiczną obsługą typów oraz pozwala na redeklarację funkcji z różnymi typami parametrów.
Jego ekosystem składa się między innymi z potężnych narzędzi do analizy i wizualizacji danych, a także uczenia maszynowego.
Zaskarbia sobie rosnące zainteresowanie w różnych dziedzinach nauki, np. biologii, fizyce czy astronomii [@packageJulia].

Z uwagi na dojrzewającą bazę bibliotek tego języka,
możliwośći pracy w zakresie modeli GARCH oraz przełącznikowych są stosunkowo ograniczone.
Wiele z oferowanych pakietów nie posiada kompletu funkcji potrzebnych do przeprowadzenia badań zawartych w bieżącej pracy.
Popularnością w tej dziedzinie cieszą się pakiety:

- `ARCHModels.jl` --
pozwala na budowanie modeli ARCH, GARCH, TGARCH oraz EGARCH.
Umożliwia także specyfikację modelu ARMA, a nawet implementuje różne rozkłady innowacji
[@packageJuliaARCHModels],

- `MarSwitching.jl` --
implementacja modeli przełącznikowych Markowa.
Pozwala na tworzenie i przewidywanie przebiegu modeli oraz definicję zmiennych zewnętrznych.
W przyszłości, w zależności od zainteresowania,
twórca planuje implementację modeli GARCH oraz różnych rozkładów innowacji
[@packageJuliaMarSwitching].
